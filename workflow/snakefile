import os
import pandas as pd

## master snakefile

## setting environmental variables
DATASET_DIR = config["dataset_dir"]
RUN_DEMUX_DADA2 = config["raw_sequences"]
TAX_CLASS = config["tax_class"]
TOTAL_SUM_SCALING = config["total_sum_scaling"]
CORE_METRICS = config["core_metrics"]
MICROBIOME_R_OUT = config["microbiome_r_outputs"]
R_SCRIPT_DIR = config["r_script_dir"]
QIIME = config["qiime_env"]

## dealing with diverging workflows (if you run/don't run total sum scaling) creating the same output to feed into core metrics analysis
if TOTAL_SUM_SCALING == 'yes':
    WHICH_OTU = "data/qiime/total_sum_otu_table.qza"
else:
    WHICH_OTU = "data/qiime/taxOnly_otu_table.qza"

## step 1
RAW_SEQ_DIR = config["raw_seq_dir"]
RAW_SEQS = config["raw_seqs"]
BARCODES = config["barcodes"]
TRIM_LFT_FOR = config["dada2_trim_left_for"]
TRIM_LFT_REV = config["dada2_trim_left_rev"]
TRUNC_LEN_FOR = config["dada2_trunc_len_for"]
TRUNC_LEN_REV = config["dada2_trunc_len_rev"]

## steps 2 and 3
BIOM = config["biom_table"]
REP_SEQS = config["rep_seqs"]

## step 4 and 5
METADATA = config["metadata"]
CORE_SAMPLING_DEPTH = config["core_metrics_sampling_depth"]
PROCESSED_META = config["processed_metadata"]

## step 6 (madis cecal analysis)
SAMPLEID_KEY = config["sampleID_key"]
MOUSEID_FACIL_KEY = config["mouseID_facil_key"]
BILE_ACID = config["bile_acid"]
TOXIN = config["toxin"]
HISTO = config["histo"]
METAB = config["metab"]
HYPOXIA = config["hypoxia"]


## defining output file paths from rules
## first need function to do this
def comb_filepaths(filepath1,
                   filepath2):
    return os.path.join(filepath1, filepath2)

proc_meta = pd.read_csv(os.path.join(DATASET_DIR, PROCESSED_META), sep = '\t')


## creating lists of inputs for rule_all
## includes outputs from step 1 (these look funky bc I'm using wildcards)
raw_seq_rule_all = [expand(os.path.join(DATASET_DIR, RAW_SEQ_DIR, "{run}_demux.qza"),
                                        run=RAW_SEQS),
                    expand(os.path.join(DATASET_DIR, RAW_SEQ_DIR, "{run}_demux_details.qza"),
                                        run=RAW_SEQS),
                    expand(os.path.join(DATASET_DIR, RAW_SEQ_DIR, "{run}_demux.qzv"),
                                        run=RAW_SEQS),
                    expand(os.path.join(DATASET_DIR, "data/qiime/{run}_table.qza"),
                                        run=RAW_SEQS),
                    expand(os.path.join(DATASET_DIR, "data/qiime/{run}_rep_seqs.qza"),
                                        run=RAW_SEQS),
                    expand(os.path.join(DATASET_DIR, "data/qiime/{run}_denoise_stats.qza"),
                                        run=RAW_SEQS),
                    os.path.join(DATASET_DIR, "data/qiime/merged_table.qza"),
                    os.path.join(DATASET_DIR, "data/qiime/merged_rep_seqs.qza")]


## taxonomic classification steps
tax_outs = ["databases/sepp-refs-silva-128.qza",
            "databases/silva-138-99-515-806-nb-classifier.qza",
            "data/qiime/tree.qza",
            "data/qiime/placements.qza",
            "data/qiime/filt_table.qza",
            "data/qiime/rem_table.qza",
            "data/qiime/taxonomy.qza",
            "data/qiime/taxonomy_filtered.qza",
            "data/qiime/taxonomy_filtered.qzv",
            "data/qiime/taxOnly_otu_table.qza",
            "data/qiime/tax_barplot.qzv"]

tax_rule_all = [comb_filepaths(DATASET_DIR, filepath) for filepath in tax_outs] 

## whether to put your data through total sum scaling or not
total_sum_outs = ["data/qiime/lacto_cecal_table.qza",
                  "data/qiime/lacto_rep_seqs.qza",
                  "data/qiime/lactoOnly_rep_seqs.fasta",
                  "data/qiime/total_sum_scaling.tsv",
                  "data/qiime/total_sum_scaling.biom",
                  "data/qiime/total_sum_scaling.qza",
                  "data/qiime/total_sum_filt_table.qza",
                  "data/qiime/total_sum_rem_table.qza",
                  "data/qiime/total_sum_tax_filt.qza",
                  "data/qiime/total_sum_tax_filt.qzv",
                  "data/qiime/total_sum_otu_table.qza"]

total_sum_rule_all = [comb_filepaths(DATASET_DIR, filepath) for filepath in total_sum_outs] 

## do you want to run core metrics analysis? 
core_metrics_outs = ["data/qiime/core_outputs/unweighted_unifrac_distance_matrix.qza",
                     "data/qiime/core_outputs/uw_dist_matrix.tsv",
                     "data/qiime/core_outputs/weighted_unifrac_distance_matrix.qza",
                     "data/qiime/core_outputs/w_dist_matrix.tsv",
                     "data/qiime/core_outputs/shannon_vector.qza",
                     "data/qiime/core_outputs/shannon_entropy.tsv",
                     "data/qiime/core_outputs/faith_pd_vector.qza",
                     "data/qiime/core_outputs/faith_pd.tsv"]

core_metrics_rule_all = [comb_filepaths(DATASET_DIR, filepath) for filepath in core_metrics_outs] 

## includes outputs from step 5 (longitudinal outputs only)
microbiome_r_outputs = ["plots/faith_pd.pdf",
                        "plots/shannon_entropy.pdf",
                        "stats/faith_lm.tsv",
                        "stats/faith_dunn.tsv",
                        "stats/shannon_lm.tsv",
                        "stats/shannon_dunn.tsv",
                        "plots/faith_stat_vis.pdf",
                        "plots/shannon_stat_vis.pdf",
                        "plots/unweighted_unifrac_pcoa.pdf",
                        "plots/weighted_unifrac_pcoa.pdf",
                        "stats/w_adonis_results.tsv",
                        "stats/uw_adonis_results.tsv",
                        "plots/rel_abun1.pdf",
                        "plots/rel_abun2.pdf",
                        "stats/rel_abun_lm.tsv",
                        "stats/rel_abun_dunn.tsv",
                        "plots/relAbun_stat_vis.pdf"]

resil_homog_outList = ["stats/wu_homogeneity.tsv",
                       "stats/wu_homog_dunn.tsv",
                       "stats/uu_homogeneity.tsv",
                       "stats/uu_homog_dunn.tsv",
                       "plots/wu_homogeneity.pdf",
                       "plots/wu_homog_stats.pdf",
                       "plots/uu_homogeneity.pdf",
                       "plots/uu_homog_stats.pdf",
                       "stats/uu_resiliency.tsv",
                       "stats/uu_resil_dunn.tsv",
                       "stats/wu_resiliency.tsv",
                       "stats/wu_resil_dunn.tsv",
                       "plots/wu_resiliency.pdf",
                       "plots/wu_resil_stats.pdf",
                       "plots/uu_resiliency.pdf",
                       "plots/uu_resil_stats.pdf"]

## snakemake gets upset if resil and homog rules aren't run bc the outputs aren't made
## so I'm fixing that w this ifelse statement
meta_cols = list(proc_meta.columns)
if "day_post_inf" not in meta_cols:
    microbiome_r_outputs
elif proc_meta.query('day_post_inf == -8').shape[0] > 0 == True:
    microbiome_r_outputs.append(resil_homog_outList)


rule_all_microbiome_r_outputs = [comb_filepaths(DATASET_DIR, filepath) for filepath in microbiome_r_outputs]

## includes outputs from step 6 - which is basically just my cecal analysis for the diet mouse cdiff dataset so it shouldn't be applicable to others
madis_cecal_analysis = ["data/misc/seq_depth.tsv",
                        PROCESSED_META,
                        "data/misc/corrected_bile_acid.tsv",
                        "data/misc/processed_neatToxin.tsv",
                        "data/misc/processed_dilutedToxin.tsv",
                        "data/misc/processed_metabolomics.tsv",
                        "data/misc/processed_histopathology.tsv",
                        "data/misc/processed_bile_acid.tsv",
                        "data/misc/processed_ratio_bileAcid.tsv",
                        "plots/faith_pd.pdf",
                        "plots/shannon_entropy.pdf",
                        "stats/faith_diet_results.tsv",
                        "stats/faith_dunn.tsv",
                        "stats/shannon_diet_results.tsv",
                        "stats/shannon_dunn.tsv",
                        "plots/faith_stat_vis.pdf",
                        "plots/shannon_stat_vis.pdf",
                        "plots/unweighted_unifrac_pcoa.pdf",
                        "plots/weighted_unifrac_pcoa.pdf",
                        "stats/w_adonis_results.tsv",
                        "stats/uw_adonis_results.tsv",
                        "plots/family_abun1.pdf",
                        "plots/family_abun2.pdf",
                        "stats/family_abun_lm.tsv",
                        "stats/family_abun_dunn.tsv",
                        "plots/famAbun_stat_vis.pdf",
                        "plots/histopathology.pdf",
                        "stats/histopathology_lm.tsv",
                        "stats/histopathology_dunn.tsv",
                        "plots/neat_toxin.pdf",
                        "plots/dil_toxin.pdf",
                        "stats/neatToxin_kruskal_test.tsv",
                        "stats/neatToxin_dunn_test.tsv",
                        "stats/dilToxin_kruskal_test.tsv",
                        "stats/dilToxin_dunn_test.tsv",
                        "plots/metabolomics.pdf",
                        "stats/metab_linear_model.tsv",
                        "stats/metab_dunn_test.tsv",
                        "stats/metab_kruskal_test.tsv"]

rule_all_madis_cecal_analysis = [comb_filepaths(DATASET_DIR, filepath) for filepath in madis_cecal_analysis]


## identifying which sections of the overall workflow to run based on the config_file (runs anything that says "yes")
## dictionary has which sections to run and what they're called
variable_dict = {"RUN_DEMUX_DADA2": RUN_DEMUX_DADA2,
                 "TAX_CLASS": TAX_CLASS,
                 "TOTAL_SUM_SCALING": TOTAL_SUM_SCALING,
                 "CORE_METRICS": CORE_METRICS,
                 "MICROBIOME_R_OUT": MICROBIOME_R_OUT}

## dictionary has the wanted output file paths for the associated sections that can be put together 
output_fps = {"RUN_DEMUX_DADA2": raw_seq_rule_all,
              "TAX_CLASS": tax_rule_all,
              "TOTAL_SUM_SCALING": total_sum_rule_all,
              "CORE_METRICS": core_metrics_rule_all,
              "MICROBIOME_R_OUT": rule_all_microbiome_r_outputs}

## dictionary has the snakemake sub-workflows associated with each section to select to include in the analysis
rules_dict = {"RUN_DEMUX_DADA2": "rules/01_demux_dada2.smk",
              "TAX_CLASS": "rules/02_phylogeny.smk",
              "TOTAL_SUM_SCALING": "rules/03_tss.smk",
              "CORE_METRICS": "rules/04_core_metrics.smk",
              "MICROBIOME_R_OUT": "rules/05_microbiome_r.smk"}


rule_all_input_list = []
for section, answer in variable_dict.items():
    if answer == 'yes':
        fps = output_fps[section]
        rule_all_input_list.append(fps)

        sub_snake = rules_dict[section]
        include: sub_snake


## rule all
rule all:
    input:
        data = rule_all_input_list